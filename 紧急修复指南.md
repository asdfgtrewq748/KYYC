# 🚨 NaN训练失败 - 紧急修复指南

## 📋 问题诊断

**症状：** 训练在 epoch 1, batch 69 出现 NaN 损失，学习率仅 0.000019

**根本原因：** 特征工程生成的 200+ 特征中存在隐藏的数值不稳定问题，即使经过多层清理仍无法完全消除

**解决方案：** 采用渐进式修复策略，从最简单配置开始逐步验证

---

## 🎯 修复策略总览

```
阶段1: 紧急模式 → 验证基础训练能否成功
   ↓ (成功)
阶段2: 启用特征工程 → 验证增强特征是否稳定
   ↓ (成功)
阶段3: 高级模型 → 切换到Transformer提升性能
   ↓ (成功)
阶段4: 完整优化 → 启用所有优化冲刺R²≥0.8
```

---

## ✅ 阶段1：紧急模式验证（必须先成功）

### 目标
- ✅ 训练不出现 NaN
- ✅ 能完整跑完 10-20 个 epoch
- ✅ R² > 0.25（基础性能）

### 配置
```
🚨 紧急模式: ✅ 启用
🔧 特征工程: ❌ 禁用（自动）
📊 模型选择: LSTM (基础版)
⚙️ 训练轮数: 20
⚙️ 批次大小: 64
⚙️ 学习率: 0.00005
⚙️ 隐藏层维度: 64
```

### 操作步骤

#### 1.1 重启程序
```bash
# 停止当前 Streamlit (Ctrl+C)
streamlit run STGCN.py
```

#### 1.2 配置紧急模式
1. 在侧边栏勾选 `🚨 紧急模式（推荐先启用）`
2. 看到警告信息：
   ```
   ⚠️ 紧急模式已启用
   - 仅使用25个基础特征（17矿压 + 8地质）
   - 禁用复杂特征工程（避免数值问题）
   ```

#### 1.3 加载数据
1. 确保勾选 `🔧 融合地质特征数据`
2. 点击 `加载数据`
3. 等待数据加载完成

#### 1.4 配置训练参数
- 模型选择：`LSTM (基础版) - 🚨 紧急模式推荐`
- 训练轮数：`20`
- 批次大小：`64`（应该已自动设置）
- 学习率：`0.00005`（应该已自动设置）
- 隐藏层维度：`64`（应该已自动设置）

#### 1.5 开始训练
点击 `🚀 开始训练`

### 预期结果

**✅ 成功标志：**
```
步骤1: 数据切分
  ✓ 训练集: 10,000 样本
  ✓ 验证集: 2,000 样本

步骤1.6: 重新归一化增强特征
  ✅ 特征深度清理+归一化完成！
  - 归一化后范围: [-2.5000, 3.8000]
  - 均值: -0.0023, 标准差: 0.9987

步骤2.1: 数据健康检查
  ✅ 训练集X 健康检查通过
  ✅ 训练集y 健康检查通过
  ✅ 验证集X 健康检查通过
  ✅ 验证集y 健康检查通过

训练过程:
  Epoch 1/20 | 训练损失: 156.23 | 验证损失: 145.67 | R²: 0.28
  Epoch 2/20 | 训练损失: 142.15 | 验证损失: 138.92 | R²: 0.31
  ...
  Epoch 20/20 | 训练损失: 98.45 | 验证损失: 102.34 | R²: 0.35
```

**❌ 如果还是失败：**

错误类型1：数据预处理异常
```
❌ 训练集 包含异常值！
- NaN数量: XXX
→ 说明：原始数据有严重问题，需要检查 CSV 文件
```

错误类型2：输入数据异常
```
❌ 检测到输入数据异常！
- Epoch: 1, Batch: XX
→ 说明：DataLoader 有问题，需要检查数据加载逻辑
```

错误类型3：训练中出现NaN
```
❌ 训练失败：检测到NaN/Inf损失！
→ 说明：模型本身有问题，需要进一步降低学习率
```

### 故障排除

如果阶段1失败，尝试：
1. 降低学习率到 `0.00001`
2. 减小批次大小到 `32`
3. 减少训练轮数到 `10`
4. 检查 CSV 文件是否有异常值

---

## ✅ 阶段2：启用特征工程（阶段1成功后）

### 目标
- ✅ 验证 264 特征训练稳定性
- ✅ R² 提升到 0.40-0.50

### 配置
```
🚨 紧急模式: ❌ 关闭
🔧 特征工程: ✅ 启用
📊 模型选择: LSTM (基础版)
⚙️ 训练轮数: 50
⚙️ 批次大小: 64
⚙️ 学习率: 0.0001
⚙️ 隐藏层维度: 64
```

### 操作步骤

1. 取消勾选 `🚨 紧急模式`
2. 勾选 `🔧 启用特征工程（高级）`
3. 重新加载数据
4. 观察特征工程输出：
   ```
   步骤1.5: 特征工程 🔧
   ✅ 特征工程完成！
   - 原始特征数: 25
   - 新增特征数: 239
   - 总特征数: 264
   
   步骤1.6: 重新归一化增强特征 🔧
   ⚠️ 训练集 发现 XXX 个极端值（如果有）
   ✅ 特征深度清理+归一化完成！
   ```
5. 开始训练

### 预期结果
- 训练损失持续下降
- R² 达到 0.40-0.50
- 无 NaN 出现

---

## ✅ 阶段3：切换高级模型（阶段2成功后）

### 目标
- ✅ 使用 Transformer 提升性能
- ✅ R² 达到 0.55-0.65

### 配置
```
🚨 紧急模式: ❌ 关闭
🔧 特征工程: ✅ 启用
📊 模型选择: Transformer (最强表达力)
⚙️ 训练轮数: 100
⚙️ 批次大小: 128
⚙️ 学习率: 0.0001
⚙️ 隐藏层维度: 128
```

---

## ✅ 阶段4：完整优化（阶段3成功后）

### 目标
- ✅ 启用所有优化
- ✅ 使用全部数据
- ✅ R² ≥ 0.80

### 配置
```
🚨 紧急模式: ❌ 关闭
🔧 特征工程: ✅ 启用
🤖 智能模式: ✅ 启用
📊 模型选择: Transformer (最强表达力)
⚙️ 训练轮数: 150
⚙️ 批次大小: 128
⚙️ 学习率: 0.0001
⚙️ 隐藏层维度: 128
```

---

## 🔧 已实施的技术修复清单

### 1. 数据清理（7层防护）
- [x] NaN 检测并替换为 0
- [x] Inf 检测并替换为中位数
- [x] 极端值裁剪（99.9% 分位数）
- [x] RobustScaler 归一化（对异常值鲁棒）
- [x] 最终范围裁剪 [-10, 10]
- [x] 训练前数据健康检查
- [x] 批次输入实时验证

### 2. 训练稳定性
- [x] 学习率降低到 0.00005（紧急模式）
- [x] Warmup 增加到 10 轮（从 0.1x 开始）
- [x] 梯度裁剪降低到 max_norm=0.5
- [x] Xavier 初始化（gain=0.5）

### 3. 紧急模式简化
- [x] 禁用复杂特征工程
- [x] 使用最简单 LSTM 模型
- [x] 数据抽样到 10k（快速验证）
- [x] 禁用组合损失和混合精度
- [x] 更小的批次大小和模型维度

---

## 📊 故障诊断流程图

```
开始训练
   ↓
数据加载失败？
   ├─ 是 → 检查 CSV 文件路径和格式
   └─ 否 ↓
   
数据健康检查失败（❌）？
   ├─ 是 → 原始数据有严重问题
   │       1. 检查 CSV 是否有非数字值
   │       2. 检查是否有整列 NaN
   │       3. 尝试重新生成数据
   └─ 否 ↓
   
输入数据异常（训练前）？
   ├─ 是 → DataLoader 问题
   │       1. 检查 batch_size 是否过大
   │       2. 检查数据类型转换
   └─ 否 ↓
   
训练中出现 NaN？
   ├─ 是 → 模型训练不稳定
   │       1. 降低学习率（除以 2）
   │       2. 减小批次大小（除以 2）
   │       3. 减小模型维度（除以 2）
   │       4. 禁用特征工程
   └─ 否 ↓
   
训练成功！R² 如何？
   ├─ R² < 0.25 → 模型欠拟合
   │              增加训练轮数或启用特征工程
   ├─ 0.25 ≤ R² < 0.50 → 基础性能
   │                      启用特征工程
   ├─ 0.50 ≤ R² < 0.70 → 良好性能
   │                      切换 Transformer
   └─ R² ≥ 0.70 → 优秀性能！
                   尝试更多优化
```

---

## 🎯 当前执行计划

**现在开始执行阶段1！**

请：
1. 保存此文件
2. 按 Ctrl+C 停止当前 Streamlit
3. 运行 `streamlit run STGCN.py`
4. 严格按照 **阶段1** 的配置进行操作
5. 报告训练结果

**记住：必须先让阶段1成功，才能进入阶段2！**
